{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">BERT tutorial: Classify spam vs no spam emails</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import the dataset (Dataset is taken from kaggle)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>641</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Category                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    641  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Category       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15481865284974095"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747/4825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15% spam emails, 85% ham emails: This indicates class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = df[df['Category']=='spam']\n",
    "df_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham = df[df['Category']=='ham']\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
    "df_ham_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ham     747\n",
       "spam    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>spam</td>\n",
       "      <td>Ever thought about living a good life with a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good stuff, will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Why haven't you replied to my text? I'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>spam</td>\n",
       "      <td>Gr8 new service - live sex video chat on your ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>ham</td>\n",
       "      <td>A boy was late 2 home. His father: \"POWER OF F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  spam\n",
       "788      spam  Ever thought about living a good life with a p...     1\n",
       "126       ham                               Good stuff, will do.     0\n",
       "147      spam  FreeMsg Why haven't you replied to my text? I'...     1\n",
       "4534     spam  Gr8 new service - live sex video chat on your ...     1\n",
       "4978      ham  A boy was late 2 home. His father: \"POWER OF F...     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['spam']=df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split it into training and test data set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3660              Wait.i will come out.. &lt;#&gt;  min:)\n",
       "4909             I'm in solihull, | do you want anything?\n",
       "4069    TBS/PERSOLVO. been chasing us since Sept for£3...\n",
       "2170    Shop till u Drop, IS IT YOU, either 10K, 5K, £...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now lets import BERT model and get embeding vectors for few sample statements</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.8435169 , -0.51327264, -0.8884573 , ..., -0.74748886,\n",
       "        -0.75314736,  0.91964495],\n",
       "       [-0.87208354, -0.50543964, -0.94446665, ..., -0.858475  ,\n",
       "        -0.7174534 ,  0.88082975]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\", \n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get embeding vectors for few sample words. Compare them using cosine similarity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_sentence_embeding([\n",
    "    \"banana\", \n",
    "    \"grapes\",\n",
    "    \"mango\",\n",
    "    \"jeff bezos\",\n",
    "    \"elon musk\",\n",
    "    \"bill gates\"\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99110866]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([e[0]],[e[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values near to 1 means they are similar. 0 means they are very different.\n",
    "Above you can use comparing \"banana\" vs \"grapes\" you get 0.99 similarity as they both are fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84703815]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[0]],[e[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing banana with jeff bezos you still get 0.84 but it is not as close as 0.99 that we got with grapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9872034]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[3]],[e[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeff bezos and Elon musk are more similar then Jeff bezos and banana as indicated above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build Model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of models you can build in tensorflow. \n",
    "\n",
    "(1) Sequential\n",
    "(2) Functional\n",
    "\n",
    "So far we have built sequential model. But below we will build functional model. More information on these two is here: https://becominghuman.ai/sequential-vs-functional-model-in-keras-20684f766057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = get_sentence_embeding(X_train)\n",
    "X_test_preprocessed = get_sentence_embeding(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/47605558/importerror-failed-to-import-pydot-you-must-install-pydot-and-graphviz-for-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer[1][0]',            \n",
      "                                 [(None, 128, 768),               'keras_layer[1][1]',            \n",
      "                                 (None, 128, 768),                'keras_layer[1][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[1][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text'), name='text', description=\"created by layer 'text'\"), but it was called on an input with incompatible shape (None, 768).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text'), name='text', description=\"created by layer 'text'\"), but it was called on an input with incompatible shape (None, 768).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"keras_layer\" \"                 f\"(type KerasLayer).\n    \n    in user code:\n    \n        File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 250, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 768) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"keras_layer\" \"                 f\"(type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 768), dtype=string)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_preprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filen8z02t86.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     72\u001b[0m     result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_cond)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope))), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     73\u001b[0m result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_training_argument\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (result,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmart_cond\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_cond)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope))), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n    File \"C:\\Users\\dabhi\\AppData\\Local\\Temp\\__autograph_generated_file5yuizebo.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"keras_layer\" \"                 f\"(type KerasLayer).\n    \n    in user code:\n    \n        File \"c:\\Users\\dabhi\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 250, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 768) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"keras_layer\" \"                 f\"(type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 768), dtype=string)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_preprocessed, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 194ms/step - loss: 0.2600 - accuracy: 0.9064 - precision: 0.8486 - recall: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2599719762802124,\n",
       " 0.9064171314239502,\n",
       " 0.8486238718032837,\n",
       " 0.9893048405647278]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154,  33],\n",
       "       [  2, 185]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90       187\n",
      "           1       0.85      0.99      0.91       187\n",
      "\n",
      "    accuracy                           0.91       374\n",
      "   macro avg       0.92      0.91      0.91       374\n",
      "weighted avg       0.92      0.91      0.91       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Inference</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8734353 ],\n",
       "       [0.92858446],\n",
       "       [0.8960864 ],\n",
       "       [0.29311982],\n",
       "       [0.13262196]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    'Enter a chance to win $5000, hurry up, offer valid until march 31, 2021',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "model.predict(reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
